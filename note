目录 :

    一. Excel
    二. Mysql
    三. python
    四. Hive
    五. 数据分析
    六. 数据架构
    七. 计算机开发相关
    八. 互联网
    九. 英文 
    10. Mac
    11. 其他


一. Excel


    <1> Excel 数字转日期

        =DATE(LEFT(A2,4),MID(A2,5,2),RIGHT(A2,2))

    <2> 生成随机数

        =rand()

        默认是 0 ~ 1 之间的随机数

        =rand()*100

    <3> 总体方差 : varp(单元格:单元格)

        总体标准差 : stdevp(单元格:单元格)

        样本方差 : var()

        样本标准差 : stdev()

        变异系数(消除量纲影响) : stdevp/mean

    <4> 中位数

        median()

    <5> 众数

        mode()

    <6> 偏度系数
    
        skew()

    <7> 峰度系数

        kurt()

    <8> 协方差

        样本 : sample     covariance.s()

        总体 : population covariance.p()

    <9> 看数据分布

        选择数据插入里选择数据透视图 -> 轴 值 均选择该列数据 -> 将值更改为计数 -> 完成

   <10> 相关系数

        correl(array1,array2)

   <11> 拼接两个日期

        =TEXT(A1,"y/m/d-")&"-"&TEXT(B1,"y/m/d")

   <12> 频率分布直方图

        1.需要两列数据 列1 : 用于分段的数 例如 5 10 15 20 25 30

                     列2 : 数据源，并非已经求好的频数，例如 1 22 17 13 25 29 29 30 30 30 11 11 12 12

        2. 数据 > 数据分析 > 直方图 > 输入数据为数据源列，接收区域为分段列，勾选标志(作用是可以带入字段名字)及图标输出

           注意 : 不能选中一整列，要直接选中数据，

   <13> 二项分布概率计算 :

        =BinomDist(success,all_time,p,cul)

        =BinomDist(成功次数，实验次数，成功概率，0概率密度，1累计概率密度)

   <14> 回归方程 :

        散点图，右键点击图中的点添加趋势线，选中显示公式

   <15> skew() 偏度 e

        <0 左偏分布 >0 右偏分布

        kurt() 峰度

        <0 扁平分布 >0 尖峰分布

        在实际分析中，通常将峰度与偏度结合使用，来判断变量的次数分布是否接近正态分布，或与正态分布的差别。

   <16> covariance.p() 总体协方差 后跟.s是样本协方差

        当>0 存在正的线性关系，即正相关，x增大y也增大

        当<0 存在负的线性关系，即负相关，x增大y会减小

        当~=0 x和y之间无线性关系，二者无关系

   <17> 求分位数

        四分位置 :

            上 : =QUARTILE(A:A,1)  

            下 : =QUARTILE(A:A,3)  

        其他分位 :

            percentile(A:A,20%)  (直接写百分比，不用加引号)



二. Mysql 

    
    <1> to_date() 

        转换为日期格式

    <1>.2 datediff(date1,date2)

        参数1<参数2，负值

        参数1>参数2，正值

    <2> mysql 获取json里的数据

        json_extract(字段,'.$键')

    <3> replace(field,willbe_replace,will_replace)

        mysql 字符串替换

    <4> -e 导出数据

        mysql -hxx -uxx -pxx -e "query statement" db > file 

        　　-h：后面跟的是链接的host（主机）

        　　-u:后面跟的是用户名

        　　-p:后面跟的是密码

        　　db:你要查询的数据库

        　　file:你要写入的文件，绝对路径

        示例 : mysql -h127.0.0.1 -uroot -p123 -e "select * from edu_iclass_areas" test > /Users/zhengcanrui/WORK/test/test.xls

        乱码问题解决 :

        mysql  --default-character-set=gbk -uroot -p   -D open_fusion -e  " select * from table1  "  > /home/apprun/test.xls

        Mac 下乱码 使用--def...=gbk
        
    <5> group by case when end

        end 后不能带 字段，但是如果想把group by 后面case when 出来的新字段，添加进select后面，直接在select后加case when ... when 和group by 相同的即可

    <6> ifnull()
    
        查询的字段如果有空值，把空值转换为第二个值

        mysql:ifnull(field,为空的话返回这个值)

    <7> where 与 having 的区别

        where 是对表本身进行筛选,约束的数据库里有的东西
        having是对查询出来的数据进行筛选,约束的查询结果中的东西

        where是一个约束声明，使用where来约束来自数据库的数据；where是在结果返回之前起作用的；where中不能使用聚合函数。
        having是一个过滤声明；在查询返回结果集以后，对查询结果进行的过滤操作；在having中可以使用聚合函数。

    <8> if函数

        if(条件判断语句，true结果,false结果)

        例如 :

            count(distinct(if(sid>60,sid,null))) 统计sid,false的不会被统计到

    <9> strcmp函数

        strcmp(str,str) or strcmp(field,field) 若是field时，一一比较每行的两个值，返回多个 0 or 1 or -1

        解释 : 若二参数完全相同，返回0
            
               若第一个长度小于第二个,返回-1
             
               其他情况，均返回1

        比较两个字符串，如果两个字符串相等，则返回0；如果根据当前的排序顺序，第一个参数小于第二个参数，则返回-1，否则返回1。

   <10> 连续3天发生购买的用户(或留存)

        SELECT * FROM ord a JOIN ord b on a.name1=b.name1 and DATEDIFF(
        b.orderdate,a.orderdate)=1 JOIN ord c on c.name1=b.name1 and 
        DATEDIFF(c.orderdate,b.orderdate)=1;

   <11> sql中null与‘ ’的区别

            null表示空，用is null判断

            ''表示空字符串，用=''判断

   <12> mysql建表设置字符集

        ; 前添加 character set utf8;

   <13> 排序 MySQL

        order by field desc (注意添加order by 并且注意顺序)

   <14> count

        count(1),count(field) 不统计Null值

        count(*) 会统计到Null值

   <15> union 

        一个查询语句 但是需要筛选出条件不同的时，用union 与 union all

        union时会去除重复值，union all合并全不值
 
   <16> 遇到group by 问题

        set sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';
  
   <17> round()

        小数位数，round(10.0000000,4) 保留4位

   <18> coalesce(ex1,ex2)

        当ex1为空时，返回ex2，不为空返回ex1
   
        coalesce(attrs['pub_page_id'],attrs['page_id']) in ('buslinepage','transferpage','stationinfo')



三. Python 


    <1>Series.value_counts()

        统计一列数据中不同数据出现的次数

        a = pd.Series(d21_accident_sw_list).value_counts()

    <2> join

        列表合并为字符串

        a = [1,2,3,4]

        '_'.join(a)

    <3> split

        字符串分割为列表

        a = '1_2_3_4'

        a.split('_',1)  #1为切割一次

    <4> pow()

        python平方函数

        pow(x,y) x的y次方

    <5> factorial

        阶乘函数

        import math 

        math.factorial(3)

    <6> 排序不改变原列表

        sorted([3,2,1])


    <7> python 词云分析

        pip install wordcloud

        简单英文词云示例 :

            with open('./note','r') as fr:
            data = fr.read()
            import matplotlib.pyplot as plt
            from wordcloud import WordCloud
            wordcloud = WordCloud().generate(data)
            # ？下面这句不知道
            %pylab inline
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis("off")

<8> Jupyter

#显示所有列
pd.set_option('display.max_columns', None)
#显示所有行
pd.set_option('display.max_rows', None)
#设置value的显示长度为100，默认为50
pd.set_option('max_colwidth',100)

#忽略错误
import warnings
warnings.filterwarnings('ignore')

    <9> python频率分布柱状图

        # d1 为原数字，a 为与之对应的出新的次数
        import pandas as pd
        import matplotlib.pyplot as plt
        d = pd.read_csv('./1.csv',header=None)
        d = list(d[0])
        d1 = list(set(d))
        a = []
        for i in d1:
        a.append(d.count(i))
        a
        # 绘制频率分布柱状图
        plt.bar(d1,a)

   <10> Pearson相关系数

        numpy :

        import numpy as np
        import pandas as pd
        pct_chg = pd.Series({'000001.SZ':-1.7391, '000002.SZ':0.6250,'000004.SZ':1.1378,'002600.SZ':0.0000,'000010.SZ':-1.0013})
        vol = pd.Series({'000001.SZ':249326.31,'000002.SZ':338224.97,'000004.SZ':211876.00,'000010.SZ':222782.00,'002600.SZ':342096.76})
        pccs = np.corrcoef(pct_chg, vol)
        print(pccs[0][1])

        # 其中 pd.Series() 里面1.存的是字段，则series的主键则是字段里的键 2.同样也可以使用列表:np.corrcoef([1,2,3],[1,2,3])[0][1]

        scipy :

        import numpy as np
        import pandas as pd
        from scipy.stats import pearsonr
        pct_chg = pd.Series({'000001.SZ':-1.7391, '000002.SZ':0.6250,'000004.SZ':1.1378,'002600.SZ':0.0000,'000010.SZ':-1.0013})
        vol = pd.Series({'000001.SZ':249326.31,'000002.SZ':338224.97,'000004.SZ':211876.00,'000010.SZ':222782.00,'002600.SZ':342096.76})
        pccs = pearsonr(pct_chg, vol)
        print(pccs[0])

   <11> python绘制三维图表

        from mpl_toolkits.mplot3d import Axes3D
        import matplotlib.pyplot as plt
        fig = plt.figure()
        ax = fig.add_subplot(111,projection='3d')
        ax.plot(d['翡翠饺子'],d['鸡肉'],d['牛肉'],label='parametric curve')
        ax.legend()
        plt.show()



四.hive


    <1> 去重计数

        count(distinct field)去重并计数

        应该选择使用 count(*) from ... where field is not null

    <2> 字段不为空

        is not null

    <3> hive 获取json里的数据
    
        get_json_object(字段,'.$键')

    <4> from_unixtime(field,'yyyy-MM-dd HH:mm:ss')
        
        时间戳转为日期时间格式,可以只转为日期，不加后面的时间
    
    <5> date_sub 时间向前偏移函数

        参数 : 日期,偏移天数

        示例 : date_sub(current_date,interval 1 day) 

               表向前偏移一天,昨天
                
    <6> date_add 时间向偏移函数

        参数 : 日期,偏移天数 

        示例 : date_add(current_date,interval 1 day)

               表向后偏移一天i,明天 

    <7> current_date 获取当前日期
        
        或 curdate()

        hivesql示例 : date_sub(current_date,7)  即可获取时间偏移

    <8> size 

        得到数组的长度(元素个数)

    <9> split(field,str)

        参数:字段,以什么分割

   <10> { [ 需要 \\转义

        " 需要 \ 转义

   <11> substr

        截图字符串

        substr(str,int,int)

        哪里开始截，第一位是1，从哪开始截就是几

   <12> substr('2020-09-25 19:02:28',6,2);

        从日期时间，可以直接截取到字符串

        或者 month(date('2020-09-25 19:02:28'))

   <13> hive 替换字符串
   
        regexp_replace(poiname,'，','_')

        汉子英文均可以

   <14> 时间戳转日期

        转为固定格式 :

        from_unixtime(create_time,'yyyy-MM-dd HH:mm:ss'),

        转为具体到分秒的格式 :

        from_unixtime(create_time)

   <15> nvl

        查询的字段如果有空值，把空值转换为第二个值

        nvl(field,为空的话返回这个值)

   <16> <>

        不等于，与 != 相当

   <17> union 

        一个查询语句 但是需要筛选出条件不同的时，用union 与 union all

   <18> group_concat()

        mysql 分组合并值

            group_concat(要被合并的字段) ... group by 以谁为分组

        分组合并后去重 及 设置分隔符

            group_concat(distinct ... SEPARATOR ';') ... group by ...

        排序(不能和分隔符共同存在)

            group_concat(distinct ... desc) ... group by ...

   <19> 20200405 转 '2020-04-05'

        concat(substr(dt,1,4),'-',substr(dt,5,2),'-',substr(dt,7,2))



五_一. 数 据 分 析 


    统计师 : 统计数据并更多的了解数据 

    数据科学 | 分析师 : 在数据中找到答案，找到可行的方向，下定结论。构建数据模型，预测未来。

    在企业中，数据分析师的主要工作是项目的负责人，是以通过数据改进、优化、提升项目为主要工作的职位。

        
    <1> 数据可用性 

        数据的可用性可以从数据的一致性、准确性、完整性、时效性及实体同一性五个方面进行考察

            数据的一致性：指数据信息系统中各相关数据信息之间相容、不产生矛盾。

            数据的准确性：指数据信息系统中每个数据表示现实物体的精准程度。人们对数据进行操作的各个环节都可能影响数据准确性。

            数据的完整性：指数据集合包含的数据完全满足对数据进行各项操作的要求。

            数据的时效性：是指在不同需求场景下数据的及时性和有效性。对应用系统而言，往往对数据时效性要求较高，过时的数据即使分析出来了也不会对实际应用产生有价值的影响。

            实体的同一性：指同一实体在各种数据源中的描述统一。一个数据集合，满足以上五个性质的程度称为该数据集合的可用性。

    理解 : 

        一致性 :

            相关的数据之间可以对的上

        准确性 :

            数据可以精确表示现实物体，人们对数据的操作不会影响数据的准确性

        完整性 :

            数据集合包含的数据可以满足之后的所有需求，数据完整不丢失

        时效性 :

            数据能在不同的场景下能按照场景要求及时出现，数据是有效、与时俱进、不过时

        实体的统一性 :

            同一实体在各种数据源中的描述统一。同一个用户只有一个userid
        
    <2> 数据冗余 

        在一个数据集中数据之间的重复。

    <3> 幸存者偏差

        通过幸存下来的人得到的结论，是有偏差的，因为其忽略了大多数人

        幸存者偏差是一个概念，说明了我们不能只通过片面的样本得到结论，是存在偏差的

    <4> CRM 客户关系管理

        Customer Relationship Management

    <5> RFM 模型

        Recency(近期)     最近一次消费 

        Frequency(频率)   消费频率

        Monetary(货币的)  消费金额

    <6> 标签化

        给其分类别，贴标签 比如某一个人是 乐观的 收入高的 北京的 聪明的 

        将某人或某物定型化或者归入某一个类， 而不是将其视为一个独立的个体。

    <7> DA

        data analyst 数据分析师 
        
        data analysis 数据分析 

        CPDA 

        CERTIFIED PROJECTS DATA ANALYST 项目数据分析师

        certified projects data analyst

    <8> VARiance 方差 var

        STandard DEViation 标准差stdev

        Coefficient of Variation 变异系数 cov   stdev/mean



    <9> skew() 偏度 e

        <0 左偏分布 >0 右偏分布

        kurt() 峰度

        <0 扁平分布 >0 尖峰分布

        在实际分析中，通常将峰度与偏度结合使用，来判断变量的次数分布是否接近正态分布，或与正态分布的差别。

   <10> covariance.p() 总体协方差 后跟.s是样本协方差

        当>0 存在正的线性关系，即正相关，x增大y也增大

        当<0 存在负的线性关系，即负相关，x增大y会减小

        当~=0 x和y之间无线性关系，二者无关系

   <11> pp

        percent point 百分点

   <12> 贡献度分析

        帕累托分析(二八法则)

        百分之二十的事物贡献了百分之80的盈利

        Excel :

        事物名 盈利 占比          累加

          1    10   b/sum($盈利)  =sum($c$2,:c2)


   <13> ROI Return On Investment

        投资回报率，利润/成本，回报/成本，即收益占投资的比重,越高越好

        ROI = (收入-成本)/成本

   <14> KPI Key Performance Indicator

        关键绩效指标

   <15> NPS Net Promoter Score

        净推荐值指标 (顾客忠诚度分析指标)

        净促进者得分，亦可称口碑，是一种计量某个客户将会向其他人推荐某个企业或服务可能性的指数。它是最流行的顾客忠诚度分析指标，专注于顾客口碑如何影响企业成长。通过密切跟踪净推荐值，企业可以让自己更加成功。

   <16> UV Unique visitor

        访问人数
    
            同个访客多次访问仅计算一个 UV 

        PV Page View
        
        访问量

            浏览量 或 点击量

        原理 :

            采集日志数据，后台进行统计去重，展现前端

   <17> DAU

        Daily Active User 日活跃用户数量

        MAU

        Month Active User 月活跃用户数量

   <18> 用户增长
        
        拉新 与 留存

        留存 : 监控留存率指标时时动态监控，例如7日前的用户，在第七日是否有使用，用有使用量的除以七日前的那一次的新增用户量

   <19> O2O Online To Offline

        线上到线下

        O2O闭环，用户从线上到线下，最后再回到线上
        只有这样，O2O才成为真正的O2O，而不是单纯的广告平台或分类信息提供者

   <20> 生命周期

        通常指从产生到消亡的全过程的时间

   <21> MAU

        月活跃用户

   <22> 分析方法总结 (https://www.sohu.com/a/315867719_120104204):

        1. 拆解主题分析 : 将一个大的主题的事情，拆解为多个子项，例如 : 营销主题，拆解为 客户分析、品类分析、区域分析、消费频率等子项去分析，都是属于营销分析。

        2. 钻取分析 : 上钻，减少维度，生成汇总数据的分析方法。下钻，从汇总数据深入到细节数据进行观察或增加维度。

        3. 对比分析 : 时间趋势分析、构成分析、同类比较分析、多指标分析(多个指标描述一个事情)、相关性分析、分组分析等。

           (1) 时间趋势分析 : 1.简单算术平均，过去这样，今后也这样。历年当月的均值为预测值。

                              2.随机性变化分析，随机性的，历年当月的作为历史数据，回归值为预测值。

           (2) 构成分析     : 饼图分析

           (3) 同类比较分析 : 相同的事物的比较，例如 属于同一个类食品销量的比较。

           (4) 多指标分析   :   统计方法的一种，图形为多边形。统计资料中有多个指标同时存在时的统计分析，是单指标统计的发展，人物的力量敏捷智力...
            
                              公司经营综合情况 : 净资产收益率 流动比率 资产经营利润率 销售利润率 存货周转率 速动比率 

           (5) 相关性分析   :   指对两个或多个具备相关性的变量元素进行分析，从而衡量两个变量因素的相关密切程度。元素之间需要存在一定的联系或者概率才可以进行

                              相关性分析。

           (6) 分组分析     : 指将客体（问卷、特征、现实）按研究要求进行分类编组，使得同组客体之间的差别小于各种客体之间的差别，进而进行分析研究的方法。其特点在于不依赖于原始资料分布的正常性假设，可以按任意规律分布，在分析既包括数量资料，又包括质量资料的混合资料时尤为重要。

                              客体 : 被研究的对象。主体 : 主体指实践活动和认识活动的承担者；客体指主体实践活动和认识活动的对象，即同认识主体相对立的外部世界。

   <23> 专项数据分析 :

        1. 明确项目分析目标。
        
        2. 查找与目标相关的数据。
        
        3. 开始分析，首先对数据进行较为宽泛的解读，然后围绕分析目标进行探索分析。

        4. 给出分析结果，并从数据上对未来进行展望。



五_二. BI 

    
    <1> 埋点开发流程 
    
        埋点需求输出 -> 需求开发排期 -> 需求开发及提测 -> 一灰

        PM写埋点需求 -> BI检查埋点需求，检查规范性、合理性 -> BI准出，RD接埋点开发需求 -> PM、BI、RD进行开发提需与排期 -> QA保证埋点质量、BI抽检埋点 -> 

        BI埋点问题反馈 1-> 埋点规范设计类问题:BI&PM负责推动解决 2-> 埋点开发质量类问题:PM负责推动解决 




六. 数 据 架 构 

    
    DMBS : 数据库管理系统

    星型模型 : 一张事实表，存其他维度表的主键，在维度表中存和事实表相同的主键以及

               主键对应的具体内容 (比如事实表品牌id列,在维度表有一列品牌id,id=1的
               
               对应阿迪达斯)

    雪花模型 : 是对星型模型的拓展，维度表不直接与事实表相连，而是连接与事实表连接

               的维度表

    ods > dwd > dws > ads

        ods : 原始数据层 
        
              operation data store 

              在业务系统中的最原始数据

              命名规范 : ods_report

        dwd : 明细数据层
        
              data warehouse detail

              经过数据清洗后的层级
              
              dwd_report 

        dws : 汇总数据层 
        
              data warehouse service 

              以分析的主题作为建表驱动，将零散的数据汇总至一张表里

              dws_report

        ads : 个性化数据层

              个性化、定制化、复杂性指标

              ads_report


七. 计算机开发相关 


    <1> API 

        应用程序编程接口

        接口，通过API交给一个程序，程序返回一个内容

    <2> SDK

        软件开发工具包

        在本地建立程序，内容传入程序中产出内容

    <3> 日志

        操作系统或软件运行时存下来的过程数据

        日志数据就是计算机操作系统、或者有些应用软件在运行时，为了在今后进行系统维护起来比较方便，而将系统、或者应用软件在运行过程中产生的各种数据（通常是：用户名、用户执行的程序名、日期、时间等）写入到一个日志文件中（通常都是以 *.log　结尾）。以便今后系统出故障时可以有据可查。

    <4> kafka

        日志系统

    <5> 灰度测试

        未上线 : 黑

        中间   : 灰

        上线   : 白

    作用 :

        在某项产品或应用正式发布前，选择特定人群试用，逐步扩大其试用者数量，以便及时发现和纠正其中的错误。

        并可以 满足部分用户抢先体验的愿望

        还可以 收集用户体验的数据与指标，获得用户的意见反馈，完善产品功能，提升产品质量。



八. 互联网 


    <1> BD 

        业务拓展和商务发展

    <2> SDE 

        高级软件开发工程师

        RD

        研发工程师

    <3> SDET

        软件测试开发工程师

    <4> QA 

        Quality Assurance

        质量把控

    <4> PM

        项目经理

    <5> DSI 

        Data Science Intellgence

        数据科学与智能

    <6> 数据BP

        business partnter 业务合作伙伴(内部数据)

    <7> PRD 与 DRD (同是需求文档) 

        PRD : PRD是产品需求文档，描述了该产品的大方向。 - 产品大方向

        DRD : DRD是交互设计文档，用来承载交互说明，并交付给前端、测试以及开发工程师参考的文档。- 产品细节



九. 英 文 

    
    <1> outliers

        异常值

    <2> insight 

        洞察

    <3> banner 

        广告横幅



10. Mac 


     <1> Mac brew 安装

        https://www.cnblogs.com/x1you/p/12506405.html

    <2> uname -a

        查看操作系统的版本

    <3> 查看文件的版本  

        file 文件



11. 其 他 


    <1> 马太效应

        指强者愈强、弱者愈弱、好的愈好，坏的愈坏，多的愈多，少的愈少的现象，广泛应用于社会心理学、教育、金融以及科学等众多领域。

    <2> 人次

        一个人多次会重复计算，指总次数

        人数

        一个人不重复计算，指总人数

        uv : 计算uv，在去重时，子项上钻需要将去重字段叠加到一起再去重。

    <3> 其他人想做指标，先查一遍

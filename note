目录 :

    一. Excel
    二. Mysql
    三. python
    四. Hive
    五. 数据分析
    六. 数据架构
    七. 计算机开发相关
    八. 互联网
    九. 英文 
    10. Mac
    11. 其他


一. Excel


    <1> Excel 数字转日期

        =DATE(LEFT(A2,4),MID(A2,5,2),RIGHT(A2,2))

    <2> 生成随机数

        =rand()

        默认是 0 ~ 1 之间的随机数

        =rand()*100

    <3> 总体方差 : varp(单元格:单元格)

        总体标准差 : stdevp(单元格:单元格)

        样本方差 : var()

        样本标准差 : stdev()

        变异系数(消除量纲影响) : stdevp/mean

    <4> 中位数

        median()

    <5> 众数

        mode()

    <6> 偏度系数
    
        skew()

    <7> 峰度系数

        kurt()

    <8> 协方差

        样本 : sample     covariance.s()

        总体 : population covariance.p()

    <9> 看数据分布

        选择数据插入里选择数据透视图 -> 轴 值 均选择该列数据 -> 将值更改为计数 -> 完成

   <10> 相关系数

        correl(array1,array2)

   <11> 拼接两个日期

        =TEXT(A1,"y/m/d-")&"-"&TEXT(B1,"y/m/d")

   <12> 频率分布直方图

        1.需要两列数据 列1 : 用于分段的数 例如 5 10 15 20 25 30

                     列2 : 数据源，并非已经求好的频数，例如 1 22 17 13 25 29 29 30 30 30 11 11 12 12

        2. 数据 > 数据分析 > 直方图 > 输入数据为数据源列，接收区域为分段列，勾选标志(作用是可以带入字段名字)及图标输出

           注意 : 不能选中一整列，要直接选中数据，

   <13> 二项分布概率计算 :

        =BinomDist(success,all_time,p,cul)

        =BinomDist(成功次数，实验次数，成功概率，0概率密度，1累计概率密度)

   <14> 回归方程 :

        散点图，右键点击图中的点添加趋势线，选中显示公式

   <15> skew() 偏度 e

        <0 左偏分布 >0 右偏分布

        kurt() 峰度

        <0 扁平分布 >0 尖峰分布

        在实际分析中，通常将峰度与偏度结合使用，来判断变量的次数分布是否接近正态分布，或与正态分布的差别。

   <16> covariance.p() 总体协方差 后跟.s是样本协方差

        当>0 存在正的线性关系，即正相关，x增大y也增大

        当<0 存在负的线性关系，即负相关，x增大y会减小

        当~=0 x和y之间无线性关系，二者无关系

   <17> 求分位数

        四分位置 :

            上 : =QUARTILE(A:A,1)  

            下 : =QUARTILE(A:A,3)  

        其他分位 :

            percentile(A:A,20%)  (直接写百分比，不用加引号)



二. Mysql 
    

    <1> to_date() 

        转换为日期格式

    <1>.2 datediff(date1,date2)

        参数1<参数2，负值

        参数1>参数2，正值

    <2> mysql 获取json里的数据

        json_extract(字段,'.$键')

    <3> replace(field,willbe_replace,will_replace)

        mysql 字符串替换

    <4> -e 导出数据

        mysql -hxx -uxx -pxx -e "query statement" db > file 

        　　-h：后面跟的是链接的host（主机）

        　　-u:后面跟的是用户名

        　　-p:后面跟的是密码

        　　db:你要查询的数据库

        　　file:你要写入的文件，绝对路径

        示例 : mysql -h127.0.0.1 -uroot -p123 -e "select * from edu_iclass_areas" test > /Users/zhengcanrui/WORK/test/test.xls

        乱码问题解决 :

        mysql  --default-character-set=gbk -uroot -p   -D open_fusion -e  " select * from table1  "  > /home/apprun/test.xls

        Mac 下乱码 使用--def...=gbk
        
    <5> group by case when end

        end 后不能带 字段，但是如果想把group by 后面case when 出来的新字段，添加进select后面，直接在select后加case when ... when 和group by 相同的即可

    <6> ifnull()
    
        查询的字段如果有空值，把空值转换为第二个值

        mysql:ifnull(field,为空的话返回这个值)

    <7> where 与 having 的区别

        where 是对表本身进行筛选,约束的数据库里有的东西
        having是对查询出来的数据进行筛选,约束的查询结果中的东西

        where是一个约束声明，使用where来约束来自数据库的数据；where是在结果返回之前起作用的；where中不能使用聚合函数。
        having是一个过滤声明；在查询返回结果集以后，对查询结果进行的过滤操作；在having中可以使用聚合函数。

    <8> if函数

        if(条件判断语句，true结果,false结果)

        例如 :

            count(distinct(if(sid>60,sid,null))) 统计sid,false的不会被统计到

    <9> strcmp函数

        strcmp(str,str) or strcmp(field,field) 若是field时，一一比较每行的两个值，返回多个 0 or 1 or -1

        解释 : 若二参数完全相同，返回0
            
               若第一个长度小于第二个,返回-1
             
               其他情况，均返回1

        比较两个字符串，如果两个字符串相等，则返回0；如果根据当前的排序顺序，第一个参数小于第二个参数，则返回-1，否则返回1。

   <10> 连续3天发生购买的用户(或留存)

        SELECT * FROM ord a JOIN ord b on a.name1=b.name1 and DATEDIFF(
        b.orderdate,a.orderdate)=1 JOIN ord c on c.name1=b.name1 and 
        DATEDIFF(c.orderdate,b.orderdate)=1;

   <11> sql中null与‘’的区别

            null表示空，用is null判断

            ''表示空字符串，用=''判断

   <12> mysql建表设置字符集

        ; 前添加 character set utf8;

   <13> 排序 MySQL

        order by field desc (注意添加order by 并且注意顺序)

   <14> count

        count(1),count(field) 不统计Null值

        count(*) 会统计到Null值

   <15> union 

        一个查询语句 但是需要筛选出条件不同的时，用union 与 union all

        union时会去除重复值，union all合并不去重
 
   <16> 遇到group by 问题

        set sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';
  
   <17> round()

        小数位数，round(10.0000000,4) 保留4位

   <18> coalesce(ex1,ex2)

        当ex1为空时，返回ex2，不为空返回ex1
   
        coalesce(attrs['pub_page_id'],attrs['page_id']) in ('buslinepage','transferpage','stationinfo')

   <19> 窗口函数 

        rank()  rank:等级

        dense_rank() dense rank:密级

        row_number() row number:行号

   <20> cast 类型转换函数

        select cast(datetime as time) from a;

        Cast(字段名 as 转换的类型 )，其中类型可以为：

        CHAR[(N)] 字符型
        DATE 日期型
        DATETIME 日期和时间型
        DECIMAL float型
        SIGNED int
        TIME 时间型



三. Python 


    <1>Series.value_counts()

        统计一列数据中不同数据出现的次数

        a = pd.Series(d21_accident_sw_list).value_counts()

    <2> join

        列表合并为字符串

        a = [1,2,3,4]

        '_'.join(a)

    <3> split

        字符串分割为列表

        a = '1_2_3_4'

        a.split('_',1)  #1为切割一次

    <4> pow()

        python平方函数

        pow(x,y) x的y次方

    <5> factorial

        阶乘函数

        import math 

        math.factorial(3)

    <6> 排序不改变原列表

        sorted([3,2,1])


    <7> python 词云分析

        pip install wordcloud

        简单英文词云示例 :

            with open('./note','r') as fr:
            data = fr.read()
            import matplotlib.pyplot as plt
            from wordcloud import WordCloud
            wordcloud = WordCloud().generate(data)
            # ？下面这句不知道
            %pylab inline
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis("off")

<8> Jupyter

#显示所有列
pd.set_option('display.max_columns', None)
#显示所有行
pd.set_option('display.max_rows', None)
#设置value的显示长度为100，默认为50
pd.set_option('max_colwidth',100)

#忽略错误
import warnings
warnings.filterwarnings('ignore')

    <9> python频率分布柱状图

        # d1 为原数字，a 为与之对应的出新的次数
        import pandas as pd
        import matplotlib.pyplot as plt
        d = pd.read_csv('./1.csv',header=None)
        d = list(d[0])
        d1 = list(set(d))
        a = []
        for i in d1:
        a.append(d.count(i))
        a
        # 绘制频率分布柱状图
        plt.bar(d1,a)

   <10> Pearson相关系数

        numpy :

        import numpy as np
        import pandas as pd
        pct_chg = pd.Series({'000001.SZ':-1.7391, '000002.SZ':0.6250,'000004.SZ':1.1378,'002600.SZ':0.0000,'000010.SZ':-1.0013})
        vol = pd.Series({'000001.SZ':249326.31,'000002.SZ':338224.97,'000004.SZ':211876.00,'000010.SZ':222782.00,'002600.SZ':342096.76})
        pccs = np.corrcoef(pct_chg, vol)
        print(pccs[0][1])

        # 其中 pd.Series() 里面1.存的是字段，则series的主键则是字段里的键 2.同样也可以使用列表:np.corrcoef([1,2,3],[1,2,3])[0][1]

        scipy :

        import numpy as np
        import pandas as pd
        from scipy.stats import pearsonr
        pct_chg = pd.Series({'000001.SZ':-1.7391, '000002.SZ':0.6250,'000004.SZ':1.1378,'002600.SZ':0.0000,'000010.SZ':-1.0013})
        vol = pd.Series({'000001.SZ':249326.31,'000002.SZ':338224.97,'000004.SZ':211876.00,'000010.SZ':222782.00,'002600.SZ':342096.76})
        pccs = pearsonr(pct_chg, vol)
        print(pccs[0])

   <11> python绘制三维图表

        from mpl_toolkits.mplot3d import Axes3D
        import matplotlib.pyplot as plt
        fig = plt.figure()
        ax = fig.add_subplot(111,projection='3d')
        ax.plot(d['翡翠饺子'],d['鸡肉'],d['牛肉'],label='parametric curve')
        ax.legend()
        plt.show()

   <12> 时间区间 pandas 

        dat = pd.date_range(start='1/04/2021', end='16/05/2021', freq='D')
        
        freq : 两个时间的间隔，D是一天，M是一个月。



四.hive


    <1> 去重计数

        count(distinct field)去重并计数

        应该选择使用 count(*) from ... where field is not null

    <2> 字段不为空

        is not null

    <3> hive 获取json里的数据
    
        get_json_object(字段,'.$键')

    <4> from_unixtime(field,'yyyy-MM-dd HH:mm:ss')
        
        时间戳转为日期时间格式,可以只转为日期，不加后面的时间
    
    <5> date_sub 时间向前偏移函数

        参数 : 日期,偏移天数

        示例 : date_sub(current_date,interval 1 day) 

               表向前偏移一天,昨天

        !!!目前证明Hive有效的昨天函数 FROM_UNIXTIME(UNIX_TIMESTAMP())
                
    <6> date_add 时间向偏移函数

        参数 : 日期,偏移天数 

        示例 : date_add(current_date,interval 1 day)

               表向后偏移一天i,明天 

    <7> current_date 获取当前日期
        
        或 curdate()

        hivesql示例 : date_sub(current_date,7)  即可获取时间偏移

    <8> size 

        得到数组的长度(元素个数)

    <9> split(field,str)

        参数:字段,以什么分割

   <10> { [ 需要 \\转义

        " 需要 \ 转义

   <11> substr

        截图字符串

        substr(str,int,int)

        哪里开始截，第一位是1，从哪开始截就是几

   <12> substr('2020-09-25 19:02:28',6,2);

        从日期时间，可以直接截取到字符串

        或者 month(date('2020-09-25 19:02:28'))

   <13> hive 替换字符串
   
        regexp_replace(poiname,'，','_')

        汉子英文均可以

   <14> 时间戳转日期

        转为固定格式 :

        from_unixtime(create_time,'yyyy-MM-dd HH:mm:ss'),

        转为具体到分秒的格式 :

        from_unixtime(create_time)

   <15> nvl

        查询的字段如果有空值，把空值转换为第二个值

        nvl(field,为空的话返回这个值)

   <16> <>

        不等于，与 != 相当

   <17> union 

        一个查询语句 但是需要筛选出条件不同的时，用union 与 union all

   <18> group_concat()

        mysql 分组合并值

            group_concat(要被合并的字段) ... group by 以谁为分组

        分组合并后去重 及 设置分隔符

            group_concat(distinct ... SEPARATOR ';') ... group by ...

        排序(不能和分隔符共同存在)

            group_concat(distinct ... desc) ... group by ...

   <19> 20200405 转 '2020-04-05'

        concat(substr(dt,1,4),'-',substr(dt,5,2),'-',substr(dt,7,2))

   <20> 视图(Hive,Oracle,Sql Server支持，Mysql不支持)

        临时视图表，减少重复sql代码
   
        WITH t1 AS (
                    SELECT *
                    FROM carinfo
                    ), 
             t2 AS (
                    SELECT *
                    FROM car_blacklist
                   )
       SELECT *
       FROM t1, t2;



五_一. 数 据 分 析 


    在公司中的工作 :

        1. 业务的决策

        2. 业务的监测

        3. 业务的收入


    <1> 数据可用性 

        数据的可用性可以从数据的一致性、准确性、完整性、时效性及实体同一性五个方面进行考察

            数据的一致性：指数据信息系统中各相关数据信息之间相容、不产生矛盾。

            数据的准确性：指数据信息系统中每个数据表示现实物体的精准程度。人们对数据进行操作的各个环节都可能影响数据准确性。

            数据的完整性：指数据集合包含的数据完全满足对数据进行各项操作的要求。

            数据的时效性：是指在不同需求场景下数据的及时性和有效性。对应用系统而言，往往对数据时效性要求较高，过时的数据即使分析出来了也不会对实际应用产生有价值的影响。

            实体的同一性：指同一实体在各种数据源中的描述统一。一个数据集合，满足以上五个性质的程度称为该数据集合的可用性。

    理解 : 

        一致性 :

            相关的数据之间可以对的上

        准确性 :

            数据可以精确表示现实物体，人们对数据的操作不会影响数据的准确性

        完整性 :

            数据集合包含的数据可以满足之后的所有需求，数据完整不丢失

        时效性 :

            数据能在不同的场景下能按照场景要求及时出现，数据是有效、与时俱进、不过时

        实体的统一性 :

            同一实体在各种数据源中的描述统一。同一个用户只有一个userid
        
    <2> 数据冗余 

        在一个数据集中数据之间的重复。

    <3> 幸存者偏差

        通过幸存下来的人得到的结论，是有偏差的，因为其忽略了大多数人

        幸存者偏差是一个概念，说明了我们不能只通过片面的样本得到结论，是存在偏差的

    <4> CRM 客户关系管理

        Customer Relationship Management

    <5> RFM 模型 百度可以查搭建方法

        Recency(近期)     最近一次消费 

        Frequency(频率)   消费频率

        Monetary(货币的)  消费金额

    <6> 标签化

        给其分类别，贴标签 比如某一个人是 乐观的 收入高的 北京的 聪明的 

        将某人或某物定型化或者归入某一个类， 而不是将其视为一个独立的个体。

    <7> DA

        data analyst 数据分析师 
        
        data analysis 数据分析 

        CPDA 

        CERTIFIED PROJECTS DATA ANALYST 项目数据分析师

        certified projects data analyst

    <8> VARiance 方差 var

        STandard DEViation 标准差stdev

        Coefficient of Variation 变异系数 cov   stdev/mean

    <9> skew() 偏度 e

        <0 左偏分布 >0 右偏分布

        kurt() 峰度

        <0 扁平分布 >0 尖峰分布

        在实际分析中，通常将峰度与偏度结合使用，来判断变量的次数分布是否接近正态分布，或与正态分布的差别。

   <10> covariance.p() 总体协方差 后跟.s是样本协方差

        当>0 存在正的线性关系，即正相关，x增大y也增大

        当<0 存在负的线性关系，即负相关，x增大y会减小

        当~=0 x和y之间无线性关系，二者无关系

   <11> pp

        percent point 百分点

   <12> 贡献度分析

        帕累托分析(二八法则)

        百分之二十的事物贡献了百分之80的盈利

        Excel :

        事物名 盈利 占比          累加

          1    10   b/sum($盈利)  =sum($c$2,:c2)

   <13> ROI Return On Investment

        投资回报率，利润/成本，回报/成本，即收益占投资的比重,越高越好

        ROI = (收入-成本)/成本

   <14> KPI Key Performance Indicator

        关键绩效指标

   <15> NPS Net Promoter Score

        净推荐值指标 (顾客忠诚度分析指标)

        净促进者得分，亦可称口碑，是一种计量某个客户将会向其他人推荐某个企业或服务可能性的指数。它是最流行的顾客忠诚度分析指标，专注于顾客口碑如何影响企业成长。通过密切跟踪净推荐值，企业可以让自己更加成功。

   <16> UV Unique visitor

        访问人数
    
            同个访客多次访问仅计算一个 UV 

        PV Page View
        
        访问量

            浏览量 或 点击量

        原理 :

            采集日志数据，后台进行统计去重，展现前端

   <17> DAU

        Daily Active User 日活跃用户数量

        MAU

        Month Active User 月活跃用户数量

   <18> 用户增长(业务增长方法论)
        
        AARRR模型 : Acquisition Activation Retention Revenue Referral

                        获取       激活      留存      变现    推荐

                    获取客户 
                    提高活跃率(活跃用户数、活跃率、使用时长、启动次数)
                    次留、周留、月留
                    获取收入
                    K-factor(K因子)

   <19> O2O Online To Offline

        线上到线下

        O2O闭环，用户从线上到线下，最后再回到线上
        只有这样，O2O才成为真正的O2O，而不是单纯的广告平台或分类信息提供者

   <20> 生命周期

        通常指从产生到消亡的全过程

   <21> MAU

        月活跃用户

   <22> 指标
   
        1. 指标体系
        
           规划数据指标体系的两个模型 :

               (1) OSM : Object 目标

                         Strategy 策略 

                         Measure 量度

               (2) UJM : User Journey Map 用户旅程地图

        2. 指标类型

           1. 数量指标

           2. 质量指标

                  (1) 相对值指标

                      (相对大的-相对基础)/相对基础 

                       观察一个数值相对另一个数值的偏离程度，通过使用相对值，得到变化程度，在图表中直接展示该程度，即展示了偏离程度。(x轴用日期，y轴百分比)

   <23> 分析思路、方法与分析模型

        起点与终点 : 
        
            以业务场景为起始思考点，以业务决策作为终点。(分析严谨，经得住拷问)

        思路 :

            挖掘业务含义 -> 制定分析计划 -> 拆分查询数据 -> 提炼业务洞察 -> 产出商业决策        

        方法 :
   
            https://www.sohu.com/a/315867719_120104204

            1. 拆解主题 : 将一个大的主题的事情，拆解为多个子项，例如 : 营销主题，拆解为 客户分析、品类分析、区域分析、消费频率等子项去分析，都是属于营销分析。

            2. 钻取 : 上钻，减少维度，生成汇总数据的分析方法。下钻，从汇总数据深入到细节数据进行观察或增加维度。(按组织树钻取，按品类树钻取，按其他维度钻取)

            3. 对比 : 时间趋势分析、构成分析、同类比较分析、多指标分析(多个指标描述一个事情)、相关性分析、分组分析等。

                (1) 时间趋势 : 1.简单算术平均，过去这样，今后也这样。历年当月的均值为预测值。

                               2.随机性变化分析，随机性的，历年当月的作为历史数据，回归值为预测值。

                (2) 构成     : 饼图分析

                (3) 同类比较 : 相同的事物的比较，例如 属于同一个类食品销量的比较。

                (4) 多指标   : 统计方法的一种，图形为多边形。统计资料中有多个指标同时存在时的统计分析，是单指标统计的发展，人物的力量敏捷智力...
            
                               公司经营综合情况 : 净资产收益率 流动比率 资产经营利润率 销售利润率 存货周转率 速动比率 

                (5) 相关性   : 指对两个或多个具备相关性的变量元素进行分析，从而衡量两个变量因素的相关密切程度。元素之间需要存在一定的联系或者概率才可以进行

                               相关性分析。

                (6) 分组     : 将数据根据不同的标签，分为多个组，列举一些指标，指将客体（问卷、特征、现实）按研究要求进行分类编组，使得同组客体之间的差别小于各种客体之间的差别，进而进行分析研究的方法。其特点在于不依赖于原始资料分布的正常性假设，可以按任意规律分布，在分析既包括数量资料，又包括质量资料的混合资料时尤为重要。

                               客体 : 被研究的对象。主体 : 主体指实践活动和认识活动的承担者；客体指主体实践活动和认识活动的对象，即同认识主体相对立的外部世界。

            具体实际应用示例 :

                (1) 画像分群
                    
                    比如考虑转化率时，需要区分移动端和Web端，以及美国用户和中国用户等不同场景，这样可以在策略优化上，有针对性的进行优化。

                (2) 趋势维度

                    了解用户或产品特征的基本表现，便于进行快速迭代，有助于决策的实时性。

                (3) 漏斗观察

                    通过漏斗分析可以从先到后的顺序了解某一用户的路劲，分析每一个转化节点的转化数据。

                    需要关注:哪一步流失最多，关注流失的人都有哪些行为。

                (4) 行为轨迹

                    行为轨迹是进行全量用户行为的还原。了解用户的行为轨迹，有助于运营团队关注具体的用户体验，发现具体问题，根据用户使用习惯设计产品，投放内容。

                (5) 留存分析

                    留存是了解行为或行为组与回访之间的联系，留存老用户的成本要远远低于获取新用户，所以分析中的留存是非常重要的指标之一。

                    除了需要关注整体用户的留存情况之外，市场团队可以关注各个渠道用户的留存度，或各类内容吸引来的注册用户的回访率。产品团队关注每一个新功能对于用户的回访的影响等。

                (6) A/B测试

                    A/B测试是对比不同产品设计／算法对结果的影响。

                    产品在上线过程中经常会使用A/B测试来测试产品效果，市场可以通过A/B测试来完成不同创意的测试。

                    要进行A/B测试有两个必备因素：

                        有足够的时间进行测试；
                        数据量和数据密度较高。
                    
                    因为当产品流量不够大的时候，做A/B测试得到统计结果是很难的。而像 LinkedIn 这样体量的公司，每天可以同时进行上千个A/B测试。所以A/B测试往往公司数据规模较大时使用会更加精准，更快得到统计的结果。

                (7) 优化建模

                    当一个商业目标与多种行为、画像等信息有关联性时，我们通常会使用数据挖掘的手段进行建模，预测该商业结果的产生。

        分析模型 :

            1. SWOT分析 (四象限分析)

               优势(Strengths)、劣势(Weaknesses)、机会(Opportunities)、威胁(Threats)

               此思维模式主要用来协助分析者分析特定的对象所处的内部外部环境，分别就上述四个方面加以考量、分析利弊得失，并用来对企业的内外部环境与自身战略的匹配与否进行分析，协助分析者明白自身的得失，找出问题的根源，并设计出相应的战略应对对策。

            2. 内外因素分析法

                        内部     外部

               可控   立即执行 相关渠道

               不可控 协调沟通 确定假设

            3. SMART

            4. 5W2H

            5. 4P理论

            6. 六顶思考帽

            7. 海盗模型(AARRR)

            8. RCV模型

            9. 阿米巴经营

           10. DOSS分析法


   <24> 专题大数据分析 

        1. 明确项目分析目标。
        
        2. 查找与目标相关的数据。
        
        3. 开始分析，首先对数据进行较为宽泛的解读，然后围绕分析目标进行探索分析。

        4. 给出分析结果，并从数据上对未来进行展望。

        例如 :

           (1) 市场购物篮分析

           (2) 重力模型

           (3) 推荐算法

           (4) 价格敏感度分析

   <25> 异动分析

        第一步 : 定位有哪些主要的维度 

        第二部 : 拆解维度 
        
                 指标组成维度 : 销售额 = 订单数 * 订单价 
                                         订单数 = 客户数 * 人均订单数

                 渠道维度 : 渠道A 渠道B 渠道C
                 
                 品类维度 : 品类A 品类B 品类C

        注意 : 定位维度以及拆解向下钻取的深度取决于经营行为可以作用到、影响的位置。

   <26> 预测

        1. 费米估计

           核心思想是对目标数值(y)进行拆解，像搭梯子一样一步一步靠近目标目标(不断寻找x来计算y，y是关于x的函数)。
   
        2. ARIMA 预测

        ARIMA模型（英语：Autoregressive Integrated Moving Average model），差分整合移动平均自回归模型，又称整合移动平均自回归模型（移动也可称作滑动），是时间序列预测分析方法之一。ARIMA(p，d，q)中，AR是“自回归”，p为自回归项数；MA为“滑动平均”，q为滑动平均项数，d为使之成为平稳序列所做的差分次数（阶数）。“差分”一词虽未出现在ARIMA的英文名称中，却是关键步骤。

   <27> 数据分析人员在企业中的作用

        1. 量化经营行为为指标，进行监控分析。及时发现问题，并追根溯源。优化企业产品健康度和整体员工的素质能力。

        2. 通过分析和挖掘，为业务提供策略和方向。通过分析和监测，支持企业能够精细化运营。

        3. 利用大数据技术帮助企业实现 企业收益>企业投入(优化提高ROI)。


五_二. BI 

    
    <1> 埋点开发流程 
    
        埋点需求输出 -> 需求开发排期 -> 需求开发及提测 -> 一灰

        PM写埋点需求 -> BI检查埋点需求，检查规范性、合理性 -> BI准出，RD接埋点开发需求 -> PM、BI、RD进行开发提需与排期 -> QA保证埋点质量、BI抽检埋点 -> 

        BI埋点问题反馈 1-> 埋点规范设计类问题:BI&PM负责推动解决 2-> 埋点开发质量类问题:PM负责推动解决 




六. 数 据 架 构 

    
    DMBS : 数据库管理系统

    星型模型 : 一张事实表，存其他维度表的主键，在维度表中存和事实表相同的主键以及

               主键对应的具体内容 (比如事实表品牌id列,在维度表有一列品牌id,id=1的
               
               对应阿迪达斯)

    雪花模型 : 是对星型模型的拓展，维度表不直接与事实表相连，而是连接与事实表连接

               的维度表

    ods > dwd > dws > ads

        ods : 原始数据层 
        
              operation data store 

              在业务系统中的最原始数据

              命名规范 : ods_report

        dwd : 明细数据层
        
              data warehouse detail

              经过数据清洗后的层级
              
              dwd_report 

        dws : 汇总数据层 
        
              data warehouse service 

              以分析的主题作为建表驱动，将零散的数据汇总至一张表里

              dws_report

        ads : 个性化数据层

              个性化、定制化、复杂性指标

              ads_report


七. 计算机开发相关 


    <1> API 

        应用程序编程接口

        接口，通过API交给一个程序，程序返回一个内容

    <2> SDK

        软件开发工具包

        在本地建立程序，内容传入程序中产出内容

    <3> 日志

        操作系统或软件运行时存下来的过程数据

        日志数据就是计算机操作系统、或者有些应用软件在运行时，为了在今后进行系统维护起来比较方便，而将系统、或者应用软件在运行过程中产生的各种数据（通常是：用户名、用户执行的程序名、日期、时间等）写入到一个日志文件中（通常都是以 *.log　结尾）。以便今后系统出故障时可以有据可查。

    <4> kafka

        日志系统

    <5> 灰度测试

        未上线 : 黑

        中间   : 灰

        上线   : 白

    作用 :

        在某项产品或应用正式发布前，选择特定人群试用，逐步扩大其试用者数量，以便及时发现和纠正其中的错误。

        并可以 满足部分用户抢先体验的愿望

        还可以 收集用户体验的数据与指标，获得用户的意见反馈，完善产品功能，提升产品质量。



八. 互联网 


    <1> BD 

        业务拓展和商务发展

    <2> SDE 

        高级软件开发工程师

        RD

        研发工程师

        开发分工程与策略，工程搭建技术框架，提供服务。策略迭代算法。

    <3> SDET

        软件测试开发工程师

    <4> QA 

        Quality Assurance

        质量把控

    <4> PM

        项目经理

    <5> DSI 

        Data Science Intellgence

        数据科学与智能

    <6> 数据BP

        business partnter 业务合作伙伴(内部数据)

    <7> PRD 与 DRD (同是需求文档) 

        PRD : PRD是产品需求文档，描述了该产品的大方向。 - 产品大方向

        DRD : DRD是交互设计文档，用来承载交互说明，并交付给前端、测试以及开发工程师参考的文档。- 产品细节

    <8> B端 与 C端 

        Consumer 个人用户端  To C

        Business 商家用户端  To B



九. 英 文 

    
    <1> outliers

        异常值

    <2> insight 

        洞察

    <3> banner 

        广告横幅



10. Mac 


     <1> Mac brew 安装

        https://www.cnblogs.com/x1you/p/12506405.html

    <2> uname -a

        查看操作系统的版本

    <3> 查看文件的版本  

        file 文件



11. 其 他 


    <1> 马太效应

        指强者愈强、弱者愈弱、好的愈好，坏的愈坏，多的愈多，少的愈少的现象，广泛应用于社会心理学、教育、金融以及科学等众多领域。

    <2> 人次

        一个人多次会重复计算，按次数计算

        人数

        一个人不重复计算，按人数计算

        uv : 计算uv，在去重时，子项上钻需要将去重字段叠加到一起再去重。

    <3> hadoop 常用指令

        hadoop fs -get /user/map_da/map_bi/XXXXX/xxxx.sh   ###hdfs下载文件
        hadoop fs -put   xxxx.sh    /user/map_da/map_bi/XXXXX/    ####上传本地文件至hdfs
        hadoop fs -rm  /user/map_da/map_bi/XXXXX/xxxx.sh    ####删除远端hdfs文件
        hadoop fs -cat /user/map_da/map_bi/XXXXX/xxxx.sh   ###预览hdfs文件
        hadoop fs -mkdir /user/map_da/map_bi/XXXXX/dir    ###hdfs上新建目录
        hadoop fs -ls /user/map_da/map_bi/XXXXX/dir   ###查看hdfs目录信息
        hadoop fs -du -h /user/map_da/map_bi/XXXXX/dir   ###查看hdfs目录下文件大小

    <4> 问题优先排序法PQM模型

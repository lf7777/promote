数据分析目录 :

    一. 数据分析
        1. 数据分析 
        2. 统计学
        3. 数据挖掘
        4. BI
    二. 工具
        1. Excel
        2. Mysql
        3. python
        4. Hive
    三. 行业
        1. 互联网
    四. 其他
        1. 开发
        2. 英文
        3. Mac
        4. 疑问
        5. 其他


一.1. 数 据 分 析 


    分析数据 :

        各行业企业经营的各种相关信息(内部数据与外部数据)

    工作方向 :

        基于业务(业务维度数据) 

        统计学知识(业务数据与统计学数据分布、假设检验、置信度等结合)

        机器学习(数据挖掘)

    工作态度 :

        摒弃主观臆想和经验主义，相信客观数据，还要多次检查逻辑的严谨性。

    负责 :

        业务的监测(稳定发展)

        业务的决策(优化调整)

    掌握 :

        分析思维方法

        数据分析工具

        业务行业知识

    核心逻辑 : 

        归纳法 : 通过事实，归纳规律。(A去世了、B去世了...，所有人都会去世)

        演绎法 : 通过信息，做出决定。从已知部分，推得未知部分。这个推理的过程称之为演绎推理。(C是人，C会去世)

        二者联系 : 归纳推理的每一个具体的案例观察结论，来自于演绎推理，演绎推理的大前提来自于归纳推理概括和总结。


    1. 分析框架、思维、方法、模型

       框架 : 从开展分析项目都产出分析结果的整体逻辑
       思维 : 产出科学的分析结果的思维方式
       方法 : 通过分析方法产出科学的分析结果，目前已经存在很多科学的分析方法，需要选择合适的方法进行分析
       模型 : 数据模型，输入数据，产出科学的分析结果，目前也已经存在很多科学的分析模型，需要选择合适的模型进行分析


        <1> 框架 

              确定 : 确定分析的目标目的，确定问题并了解情况
              
              分解 : 使用正确的心智模型，分解问题与数据

              评估 : 作出各种结论

              决策 : 作出一个决策

              按顺序执行 确定>分解>评估>决策 的固定流程，同时通过经验数据来仔细推敲证据(各种问题)，即是数据分析

              确定问题-使用正确的心智模型-用该心智模型去观察外界

                确定分析的目标目的
                    目标:做到什么事情。如何指导:了解现状、指点迷津、刷新认知、方案调整、原因定位、战略升级等 
                确定问题及并了解基本情况
                    确定主要问题，准确定位核心问题，了解基本、目前的现状情况，使问题更完整、更具体，增加基础假设
                     1.5W2H问题分析法。
                     2.结合分析目的，向客户了解情况。摸清客户心思，了解客户期望，只有解决客户的期望，分析越有可能派上用场
                       (1)不停地问'是多少',使各种目标和确信观点得到量化
                       (2)预见客户的想法，他一定会关心竞争对手的情况
                       (3)对某些数据感到好奇吧?问吧!
                思路
                    针对问题，结合目标，梳理分析思路，确定相关对象指标的定义和衡量标准
                        通过分析什么预测可以了解到什么。可以换位思考，提供哪些东西会影响需求人，强调影响
                        例:通过货品分析，了解到该平台品类销售情况和产品的价格带在哪个位置，以此可以进行ABC分类的优化和了解平台产品定位，并尝试定位产品低评的原因

                分解问题与数据
                    使用正确的心智模型(结合主要问题)，化大为小，分解问题与数据，确定主要分析方向
                        了解分解:对了解到的情况进行总结，提炼确信观点
                        数据分解:1.尝试分解最重要因子的最好起步办法是找出高效的比较因子 2.下钻等
                    方法
                        划分为可管理、可解决的组块，逻辑树或公式，相互独立、完全穷尽，有重点的分析(问题优先级排序PQM模型)。通过回答大问题分解出来的小问题，就可以找到大问题的答案
                        其他视角:根据具体情况、判断，分解出可能存在的其他组块视角，大胆假设，小心验证
                        例:如何提高销量?划分为 1.哪种广告方式最有可能产生效果?2.我们的广告做的怎么样了?

                评估
                    应用适合的分析思维、方法或模型仔细推敲证据(各种问题)

                决策 
                    背景
                        重点描述对象的现状困境问题，与分析呼应。
                        用讲故事的方式呈现 : 背景-冲突-疑问-回答
                        例如:农药植保需要人工完成，工作强度大，人员易中毒，工作效率低，每年全国因农药中毒的人数达数万人。
                    结论
                        作出各种结论
                        有的放矢，精炼
                        结论先行:每个报告只有一个中心思想，并放在报告的最前面
                        以上统下:每一层次上的思想必须是对下一层次思想的总结概括。越往金字塔上层的结论价值越高。
                        归纳分组:每一组中的思想必须属于同一逻辑范畴
                        逻辑递进:每一组中的思想观点必须按照逻辑顺序排列
                    决策
                        针对问题，重新组合结论在一起，作出(建议)一个决策

              备注 
                心智模型 
                    心智模型就是看法
                    心智模型决定对问题和数据的观察结果。心智模型就是对外界的假设和确信的观点，务必明确心智模型，妥善利用
                    心智模型应当包括不了解的因素，一定要指出不确定因素，会揭示出未知信息，发现盲点
                    确定问题-使用正确的心智模型-用该心智模型去观察外界
                    回顾问题-更换心智模型-用新的模型去观察
                报告原则
                    你提交给客户的报告要以得到客户理解、鼓励客户以数据为基础作出明智的决策为重点。(客观，不带主观臆断)
                项目评估
                    在分析结束后，跟进目标、方案或决策的完成情况，对自己的分析能力进行总结与提高


        <2> 思维

            基本思维 : 目标 : 北极星，以终为始
                       对比 : 对比得高低，高低得结论
                       细分 : 细化问题，有的放矢
                       归纳 : 总结个体到一般规律
                       演绎 : 通过一般规律到个体
            
            探索思维 : 溯源 : 追本溯源，寻找源头、缘由
                       相关 : 相关性
                       假设 : 大胆假设，小心求证
                       逆向 : 从结果出发

            (1) 目标思维 :

                以终为始，明确目标，围绕目标，才不会迷失方向，目标作为北极星，始终向着目前前进，直到到达目标

                正确定义问题、合理分解问题、抓住关键问题

            (2) 对比思维 :

                对比得高低，通过高低得结论

                同环比、与目标比、来源比 
                同类比:普通同类比较，分组后比较，构成(同类占比情况饼图)，多指标分析(多指标描述某一个事物)，分组后比较(人为划组后，比较指标)

            (3) 细分思维 :

                在明确金字塔顶问题后，运用细分思维拆解问题。在拆解的过程中，要做到有的放矢(细分后的问题有用，实际可以作用到)，细分的方式合理

                常见细分方式 : 时间、空间、过程、公式、模型

            (4) 溯源思维 :

                细分拆解问题的时或者到达底层后，通过对问题提问为什么的方式，追寻发生此问题的本质原因(追寻完再追寻，直到无法追寻或源头无法作用，无法优化为止)

                追本溯源

            (5) 相关思维 :

                用来找相关性。是变量间的关联程度，结果只证明了相关性，非因果关系(改变x不能改变y)

                步骤 : 收集相关数据->绘制散点图->计算相关系数

            (6) 假设思维 :

                彻底颠覆旧思想，大胆做出假设，小心求证假设

                步骤 : 提出假设->统计检验->做出判断

            (7) 逆向思维 :
                    
                正向 : 从自身习惯性角度出发

                逆向 : 从结果出发

                正向思维是指延着人们的习惯性思考路线去思考，逆向思维则是背逆人们的习惯路线去思维

                常见逆向思维 : 结构逆向、功能逆向、状态、原理、方法

            (8) 归纳思维 :
                    
                从个体到一般
                总结现象，得出规律

                金、银、铜、铁等金属分别能导电，归纳出结论:所有金属都能导电

                            求同法
                            求异法
                归纳方法    共用法
                            共变法
                            剩余法

            (9) 演绎思维 :

                从一般到个体
                利用规律，得出结论

                大前提     小前提   结论
                规律       变量     结论
                金属能导电 铜是金属 铜能导电

                                    不要出现第四个概念
                                    中项要能向外延伸
                 遵循五项基本原则   大项和小项都不能扩大
                                    前提都为否，结论不必然
                                    前提有一否，结论必为否

            备注 :
         
                多指标   : 多边图形，单指标统计的发展，多指标共同描述一个事物，例如人物的力量敏捷智力，企业经营的净资产收益率 流动比率 资产经营利润率 销售利润率 存货周转率

                分组     : 将数据根据不同的标签，分为多个组，列举一些指标，指将客体（问卷、特征、现实）按研究要求进行分类编组，使得同组客体之间的差别小于各种客体之间的差别，进而进行分析研究的方法。其特点在于不依赖于原始资料分布的正常性假设，可以按任意规律分布，在分析既包括数量资料，又包括质量资料的混合资料时尤为重要。
                       客体 : 被研究的对象。主体 : 主体指实践活动和认识活动的承担者；客体指主体实践活动和认识活动的对象，即同认识主体相对立的外部世界。

                拆解主题 : 将一个大的主题的事情，拆解为多个子项，例如 : 营销主题，拆解为 客户分析、品类分析、区域分析、消费频率等子项去分析，都是属于营销分析。

                https://www.sohu.com/a/315867719_120104204


        <3> 方法

            (1) 画像分群
                    
                比如考虑转化率时，需要区分移动端和Web端，以及美国用户和中国用户等不同场景，这样可以在策略优化上，有针对性的进行优化。

            (2) 趋势维度

                了解用户或产品特征的基本表现，便于进行快速迭代，有助于决策的实时性。

            (3) 漏斗观察

                通过漏斗分析可以从先到后的顺序了解某一用户的路劲，分析每一个转化节点的转化数据。

            (4) 需要关注 : 哪一步流失最多，关注流失的人都有哪些行为。

            (5) 行为轨迹

                行为轨迹是进行全量用户行为的还原。了解用户的行为轨迹，有助于运营团队关注具体的用户体验，发现具体问题，根据用户使用习惯设计产品，投放内容。

            (6) 留存分析

                留存是了解行为或行为组与回访之间的联系，留存老用户的成本要远远低于获取新用户，所以分析中的留存是非常重要的指标之一。

                除了需要关注整体用户的留存情况之外，市场团队可以关注各个渠道用户的留存度，或各类内容吸引来的注册用户的回访率。产品团队关注每一个新功能对于用户的回访的影响等。

            (9) 象限法

        <4> 模型

            (1) SWOT分析 (四象限分析)

               优势(Strengths)、劣势(Weaknesses)、机会(Opportunities)、威胁(Threats)
               此思维模式主要用来协助分析者分析特定的对象所处的内部外部环境，分别就上述四个方面加以考量、分析利弊得失，并用来对企业的内外部环境与自身战略的匹配与否进行分析，协助分析者明白自身的得失，找出问题的根源，并设计出相应的战略应对对策。

            (2) 内外因素分析法

                         内部     外部
                可控   立即执行 相关渠道
                不可控 协调沟通 确定假设

            (3) SMART

            (4) 5W2H

            (5) 4P理论

            (6) 六顶思考帽

            (7) 海盗模型(AARRR)

            (9) RCV模型

           (10) 阿米巴经营

           (11) DOSS分析法

           (12) RFM 模型

                Recency(近期)     最近一次消费 

                Frequency(频率)   消费频率

                Monetary(货币的)  消费金额

           (13) 帕累托分析(贡献度分析，二八法则)

                百分之二十的事物贡献了百分之80的盈利，按照盈利做降序，对占比进行累加运算

                Excel计算实现 :

                事物名 盈利      占比          累加

                   1    10   b/sum($盈利)  =sum($c$2,:c2)


    2. 指标

        自 定 义 指 标 :

        <1> 核心指标

            根据业务应当关注的方向定义具体指标

        <2> 相对值指标

            (相对大的-相对基础)/相对基础 

            观察一个数值相对另一个数值的偏离程度，通过使用相对值，得到变化程度，在图表中直接展示该程度，即展示了偏离程度。(x轴用日期，y轴百分比)

        模板指标 :

        <1> 活跃指标

            Dau Wau Mau 

        <2> ROI 
   
            Return On Investment

            投资回报率，利润/成本，回报/成本，即收益占投资的比重,越高越好

            ROI = (收入-成本)/成本

        <3> KPI 
   
            Key Performance Indicator

            关键绩效指标

        <4> NPS 
   
            Net Promoter Score

             净推荐值指标 (顾客忠诚度分析指标)

             净促进者得分，亦可称口碑，是一种计量某个客户将会向其他人推荐某个企业或服务可能性的指数。它是最流行的顾客忠诚度分析指标，专注于顾客口碑如何影响企业成长。通过密切跟踪净推荐值，企业可以让自己更加成功。

        <5> CAC 

            用户获取成本

        指 标 模 型 :
        
           <1> OSM : Object 目标

                     Strategy 策略 

                     Measure 量度

           <2> UJM : User Journey Map 用户旅程地图


    3. 专项分析

        <1> 词频分析
            
            图悦

            链接 : http://www.picdata.cn/picdata/index.php

    4. 异动分析

        第一步 : 定位有哪些主要的维度 

        第二部 : 拆解维度 
        
                 指标公式维度 : 销售额 = 订单数 * 订单价 
                                         订单数 = 客户数 * 人均订单数

                 渠道维度 : 渠道A 渠道B 渠道C
                 
                 品类维度 : 品类A 品类B 品类C

        注意 : 定位维度以及拆解向下钻取的深度取决于经营行为涉及、可以作用影响的位置。


    5. 预测

        <1> 费米估计

            核心思想是对目标数值(y)进行拆解，像搭梯子一样一步一步靠近目标目标(不断寻找x来计算y，y是关于x的函数)。
   
        <2> ARIMA 预测

        ARIMA模型（英语：Autoregressive Integrated Moving Average model），差分整合移动平均自回归模型，又称整合移动平均自回归模型（移动也可称作滑动），是时间序列预测分析方法之一。ARIMA(p，d，q)中，AR是“自回归”，p为自回归项数；MA为“滑动平均”，q为滑动平均项数，d为使之成为平稳序列所做的差分次数（阶数）。“差分”一词虽未出现在ARIMA的英文名称中，却是关键步骤。


    6. 用户增长

        生命周期 : 指从产生到消亡的全过程
        
        AARRR模型 : Acquisition Activation Retention Revenue Referral    用户增长方法论

                        获取       激活      留存      变现    推荐

                    获取客户 
                    提高活跃率(活跃用户数、活跃率、使用时长、启动次数)
                    次留、周留、月留
                    获取收入
                    K-factor(K因子)

    7. 报表

        基本报表应从多个重要维度展示数据

    8. A/B测试

        A/B测试是对比不同产品设计／算法对结果的影响。

        产品在上线过程中经常会使用A/B测试来测试产品效果，市场可以通过A/B测试来完成不同创意的测试。

        要进行A/B测试有两个必备因素：

            有足够的时间进行测试；
            数据量和数据密度较高。

    9. 建模

        当一个商业目标与多种行为、画像等信息有关联性时，我们通常会使用数据挖掘的手段进行建模，预测该商业结果的产生。

   10. 其他概念 
 
        <1> 幸存者偏差

            通过幸存下来的人得到的结论，是有偏差的，因为其忽略了大多数人

            幸存者偏差是一个概念，说明了我们不能只通过片面的样本得到结论，是存在偏差的

        <2> 马太效应

            指强者愈强、弱者愈弱、好的愈好，坏的愈坏，多的愈多，少的愈少的现象，广泛应用于社会心理学、教育、金融以及科学等众多领域。
            
    <> 数据的可用性(基础特性) 

        一致性 :

            相关的数据之间可以对的上

        准确性 :

            数据可以精确表示现实物体，人们对数据的操作不会影响数据的准确性

        完整性 :

            数据集合包含的数据可以满足之后的所有需求，数据完整不丢失，不冗余(不重复)

        时效性 :

            数据能在不同的场景下能按照场景要求及时出现，数据是有效、与时俱进、不过时

        实体的统一性 :

            同一实体在各种数据源中的描述统一。同一个用户只有一个userid
            

        数据的可用性可以从数据的一致性、准确性、完整性、时效性及实体同一性五个方面进行考察

            数据的一致性：指数据信息系统中各相关数据信息之间相容、不产生矛盾。

            数据的准确性：指数据信息系统中每个数据表示现实物体的精准程度。人们对数据进行操作的各个环节都可能影响数据准确性。

            数据的完整性：指数据集合包含的数据完全满足对数据进行各项操作的要求。

            数据的时效性：是指在不同需求场景下数据的及时性和有效性。对应用系统而言，往往对数据时效性要求较高，过时的数据即使分析出来了也不会对实际应用产生有价值的影响。

            实体的同一性：指同一实体在各种数据源中的描述统一。一个数据集合，满足以上五个性质的程度称为该数据集合的可用性。


一.2. 统计学


    <8> VARiance 方差 var

        STandard DEViation 标准差stdev

        Coefficient of Variation 变异系数 cov   stdev/mean

    <9> skew() 偏度 e

        <0 左偏分布 >0 右偏分布

        kurt() 峰度

        <0 扁平分布 >0 尖峰分布

        在实际分析中，通常将峰度与偏度结合使用，来判断变量的次数分布是否接近正态分布，或与正态分布的差别。

   <10> covariance.p() 总体协方差 后跟.s是样本协方差

        当>0 存在正的线性关系，即正相关，x增大y也增大

        当<0 存在负的线性关系，即负相关，x增大y会减小

        当~=0 x和y之间无线性关系，二者无关系

   <11> pp

        percent point 百分点


一.3. 数据挖掘


       方向 : 挖掘数据判断未来

       理论 : 机器学习算法等


一.4. BI 


    方向 : 搭建业务维度数据报表

           了解数据

           整合数据

           展示数据

           搭建bi报表可以很大程度解决数据分析师的工作，推动全部门的数据意识，降低其他部门的数据需求。


    1. 数据架构

        <1> 数仓层级

            ods > dwd > dws > ads

                ods : 原始数据层 
        
                      operation data store 

                      在业务系统中的最原始数据

                      命名规范 : ods_report

                dwd : 明细数据层
        
                      data warehouse detail

                     经过数据清洗后的层级
              
                      dwd_report 

                dws : 汇总数据层 
        
                      data warehouse service 

                      以分析的主题作为建表驱动，将零散的数据汇总至一张表里
 
                      dws_report

                ads : 个性化数据层

                      个性化、定制化、复杂性指标

                      ads_report


        <2> 数据模型

            星型模型 : 一张事实表，存其他维度表的主键，在维度表中存和事实表相同的主键以及

                       主键对应的具体内容 (比如事实表品牌id列,在维度表有一列品牌id,id=1的
               
                       对应阿迪达斯)

            雪花模型 : 是对星型模型的拓展，维度表不直接与事实表相连，而是连接与事实表连接

                       的维度表

        <3> 报表

        <4> 埋点开发
    
            埋点需求输出 -> 需求开发排期 -> 需求开发及提测 -> 一灰

            PM写埋点需求 -> BI检查埋点需求，检查规范性、合理性 -> BI准出，RD接埋点开发需求 -> PM、BI、RD进行开发提需与排期 -> QA保证埋点质量、BI抽检埋点 -> 

            BI埋点问题反馈 1-> 埋点规范设计类问题:BI&PM负责推动解决 2-> 埋点开发质量类问题:PM负责推动解决 



二.1. Excel


    <1> Excel 数字转日期

        =DATE(LEFT(A2,4),MID(A2,5,2),RIGHT(A2,2))

    <2> 生成随机数

        =rand()

        默认是 0 ~ 1 之间的随机数

        =rand()*100

    <3> 总体方差 : varp(单元格:单元格)

        总体标准差 : stdevp(单元格:单元格)

        样本方差 : var()

        样本标准差 : stdev()

        变异系数(消除量纲影响) : stdevp/mean

    <4> 中位数

        median()

    <5> 众数

        mode()

    <6> 偏度系数
    
        skew()

    <7> 峰度系数

        kurt()

    <8> 协方差

        样本 : sample     covariance.s()

        总体 : population covariance.p()

    <9> 看数据分布

        选择数据插入里选择数据透视图 -> 轴 值 均选择该列数据 -> 将值更改为计数 -> 完成

   <10> 相关系数

        correl(array1,array2)

   <11> 拼接两个日期

        =TEXT(A1,"y/m/d-")&"-"&TEXT(B1,"y/m/d")

   <12> 频率分布直方图

        1.需要两列数据 列1 : 用于分段的数 例如 5 10 15 20 25 30

                     列2 : 数据源，并非已经求好的频数，例如 1 22 17 13 25 29 29 30 30 30 11 11 12 12

        2. 数据 > 数据分析 > 直方图 > 输入数据为数据源列，接收区域为分段列，勾选标志(作用是可以带入字段名字)及图标输出

           注意 : 不能选中一整列，要直接选中数据，

   <13> 二项分布概率计算 :

        =BinomDist(success,all_time,p,cul)

        =BinomDist(成功次数，实验次数，成功概率，0概率密度，1累计概率密度)

   <14> 回归方程 :

        散点图，右键点击图中的点添加趋势线，选中显示公式

   <15> skew() 偏度 e

        <0 左偏分布 >0 右偏分布

        kurt() 峰度

        <0 扁平分布 >0 尖峰分布

        在实际分析中，通常将峰度与偏度结合使用，来判断变量的次数分布是否接近正态分布，或与正态分布的差别。

   <16> covariance.p() 总体协方差 后跟.s是样本协方差

        当>0 存在正的线性关系，即正相关，x增大y也增大

        当<0 存在负的线性关系，即负相关，x增大y会减小

        当~=0 x和y之间无线性关系，二者无关系

   <17> 求分位数

        四分位置 :

            上 : =QUARTILE(A:A,1)  

            下 : =QUARTILE(A:A,3)  

        其他分位 :

            percentile(A:A,20%)  (直接写百分比，不用加引号)


二.2. Mysql 
    

    <1> to_date() 

        转换为日期格式

    <1>.2 datediff(date1,date2)

        参数1<参数2，负值

        参数1>参数2，正值

    <2> mysql 获取json里的数据

        json_extract(字段,'.$键')

    <3> replace(field,willbe_replace,will_replace)

        mysql 字符串替换

    <4> -e 导出数据

        mysql -hxx -uxx -pxx -e "query statement" db > file 

        　　-h：后面跟的是链接的host（主机）

        　　-u:后面跟的是用户名

        　　-p:后面跟的是密码

        　　db:你要查询的数据库

        　　file:你要写入的文件，绝对路径

        示例 : mysql -h127.0.0.1 -uroot -p123 -e "select * from edu_iclass_areas" test > /Users/zhengcanrui/WORK/test/test.xls

        乱码问题解决 :

        mysql  --default-character-set=gbk -uroot -p   -D open_fusion -e  " select * from table1  "  > /home/apprun/test.xls

        Mac 下乱码 使用--def...=gbk
        
    <5> group by case when end

        end 后不能带 字段，但是如果想把group by 后面case when 出来的新字段，添加进select后面，直接在select后加case when ... when 和group by 相同的即可

    <6> ifnull()
    
        查询的字段如果有空值，把空值转换为第二个值

        mysql:ifnull(field,为空的话返回这个值)

    <7> where 与 having 的区别

        where 是对表本身进行筛选,约束的数据库里有的东西
        having是对查询出来的数据进行筛选,约束的查询结果中的东西

        where是一个约束声明，使用where来约束来自数据库的数据；where是在结果返回之前起作用的；where中不能使用聚合函数。
        having是一个过滤声明；在查询返回结果集以后，对查询结果进行的过滤操作；在having中可以使用聚合函数。

    <8> if函数

        if(条件判断语句，true结果,false结果)

        例如 :

            count(distinct(if(sid>60,sid,null))) 统计sid,false的不会被统计到，标准格式，false的值只有在写null时不会统计其他的。

    <9> strcmp函数

        strcmp(str,str) or strcmp(field,field) 若是field时，一一比较每行的两个值，返回多个 0 or 1 or -1

        解释 : 若二参数完全相同，返回0
            
               若第一个长度小于第二个,返回-1
             
               其他情况，均返回1

        比较两个字符串，如果两个字符串相等，则返回0；如果根据当前的排序顺序，第一个参数小于第二个参数，则返回-1，否则返回1。

   <10> 连续3天发生购买的用户(或留存)

        SELECT * FROM ord a JOIN ord b on a.name1=b.name1 and DATEDIFF(
        b.orderdate,a.orderdate)=1 JOIN ord c on c.name1=b.name1 and 
        DATEDIFF(c.orderdate,b.orderdate)=1;

   <11> sql中null与‘’的区别

            null表示空，用is null判断

            ''表示空字符串，用=''判断

   <12> mysql建表设置字符集

        ; 前添加 character set utf8;

   <13> 排序 MySQL

        order by field desc (注意添加order by 并且注意顺序)

   <14> count

        count(1),count(field) 不统计Null值

        count(*) 会统计到Null值

   <15> union 

        一个查询语句 但是需要筛选出条件不同的时，用union 与 union all

        union时会去除重复值，union all合并不去重
 
   <16> 遇到group by 问题

        set sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';
  
   <17> round()

        小数位数，round(10.0000000,4) 保留4位

   <18> coalesce(ex1,ex2)

        当ex1为空时，返回ex2，不为空返回ex1
   
        coalesce(attrs['pub_page_id'],attrs['page_id']) in ('buslinepage','transferpage','stationinfo')

   <19> 窗口函数 

        rank()  rank:等级

        dense_rank() dense rank:密级

        row_number() row number:行号

   <20> cast 类型转换函数

        select cast(datetime as time) from a;

        Cast(字段名 as 转换的类型 )，其中类型可以为：

        CHAR[(N)] 字符型
        DATE 日期型
        DATETIME 日期和时间型
        DECIMAL float型
        SIGNED int
        TIME 时间型

   <21> order by 

        默认升序

        desc 降序 

        order by field desc 


二.3. Python 


    <1>Series.value_counts()

        统计一列数据中不同数据出现的次数

        a = pd.Series(d21_accident_sw_list).value_counts()

    <2> join

        列表合并为字符串

        a = [1,2,3,4]

        '_'.join(a)

    <3> split

        字符串分割为列表

        a = '1_2_3_4'

        a.split('_',1)  #1为切割一次

    <4> pow()

        python平方函数

        pow(x,y) x的y次方

    <5> factorial

        阶乘函数

        import math 

        math.factorial(3)

    <6> 排序不改变原列表

        sorted([3,2,1])

    <7> python 词云分析

        pip install wordcloud

        简单英文词云示例 :

            with open('./note','r') as fr:
            data = fr.read()
            import matplotlib.pyplot as plt
            from wordcloud import WordCloud
            wordcloud = WordCloud().generate(data)
            # ？下面这句不知道
            %pylab inline
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis("off")

<8> Jupyter

#显示所有列
pd.set_option('display.max_columns', None)
#显示所有行
pd.set_option('display.max_rows', None)
#设置value的显示长度为100，默认为50
pd.set_option('max_colwidth',100)

#忽略错误
import warnings
warnings.filterwarnings('ignore')

    <9> python频率分布柱状图

        # d1 为原数字，a 为与之对应的出新的次数
        import pandas as pd
        import matplotlib.pyplot as plt
        d = pd.read_csv('./1.csv',header=None)
        d = list(d[0])
        d1 = list(set(d))
        a = []
        for i in d1:
        a.append(d.count(i))
        a
        # 绘制频率分布柱状图
        plt.bar(d1,a)

   <10> Pearson相关系数

        numpy :

        import numpy as np
        import pandas as pd
        pct_chg = pd.Series({'000001.SZ':-1.7391, '000002.SZ':0.6250,'000004.SZ':1.1378,'002600.SZ':0.0000,'000010.SZ':-1.0013})
        vol = pd.Series({'000001.SZ':249326.31,'000002.SZ':338224.97,'000004.SZ':211876.00,'000010.SZ':222782.00,'002600.SZ':342096.76})
        pccs = np.corrcoef(pct_chg, vol)
        print(pccs[0][1])

        # 其中 pd.Series() 里面1.存的是字段，则series的主键则是字段里的键 2.同样也可以使用列表:np.corrcoef([1,2,3],[1,2,3])[0][1]

        scipy :

        import numpy as np
        import pandas as pd
        from scipy.stats import pearsonr
        pct_chg = pd.Series({'000001.SZ':-1.7391, '000002.SZ':0.6250,'000004.SZ':1.1378,'002600.SZ':0.0000,'000010.SZ':-1.0013})
        vol = pd.Series({'000001.SZ':249326.31,'000002.SZ':338224.97,'000004.SZ':211876.00,'000010.SZ':222782.00,'002600.SZ':342096.76})
        pccs = pearsonr(pct_chg, vol)
        print(pccs[0])

   <11> python绘制三维图表

        from mpl_toolkits.mplot3d import Axes3D
        import matplotlib.pyplot as plt
        fig = plt.figure()
        ax = fig.add_subplot(111,projection='3d')
        ax.plot(d['翡翠饺子'],d['鸡肉'],d['牛肉'],label='parametric curve')
        ax.legend()
        plt.show()

   <12> 时间区间 pandas 

        dat = pd.date_range(start='1/04/2021', end='16/05/2021', freq='D')
        
        freq : 两个时间的间隔，D是一天，M是一个月。


二.4. hive


    <1> 去重计数

        count(distinct field)去重并计数

        应该选择使用 count(*) from ... where field is not null

    <2> 字段不为空

        is not null

    <3> hive 获取json里的数据
    
        get_json_object(字段,'.$键')

    <4> from_unixtime(field,'yyyy-MM-dd HH:mm:ss')
        
        时间戳转为日期时间格式,可以只转为日期，不加后面的时间
    
    <5> date_sub 时间向前偏移函数

        参数 : 日期,偏移天数

        示例 : date_sub(current_date,interval 1 day) 

               表向前偏移一天,昨天

        !!!目前证明Hive有效的昨天函数 FROM_UNIXTIME(UNIX_TIMESTAMP())
                
    <6> date_add 时间向偏移函数

        参数 : 日期,偏移天数 

        示例 : date_add(current_date,interval 1 day)

               表向后偏移一天i,明天 

    <7> current_date 获取当前日期
        
        或 curdate()

        hivesql示例 : date_sub(current_date,7)  即可获取时间偏移

    <8> size 

        得到数组的长度(元素个数)

    <9> split(field,str)

        参数:字段,以什么分割

   <10> { [ 需要 \\转义

        " 需要 \ 转义

   <11> substr

        截图字符串

        substr(str,int,int)

        哪里开始截，第一位是1，从哪开始截就是几

   <12> substr('2020-09-25 19:02:28',6,2);

        从日期时间，可以直接截取到字符串

        或者 month(date('2020-09-25 19:02:28'))

   <13> hive 替换字符串
   
        regexp_replace(poiname,'，','_')

        汉子英文均可以

   <14> 时间戳转日期

        转为固定格式 :

        from_unixtime(create_time,'yyyy-MM-dd HH:mm:ss'),

        转为具体到分秒的格式 :

        from_unixtime(create_time)

   <15> nvl

        查询的字段如果有空值，把空值转换为第二个值

        nvl(field,为空的话返回这个值)

   <16> <>

        不等于，与 != 相当

   <17> union 

        一个查询语句 但是需要筛选出条件不同的时，用union 与 union all

   <18> group_concat()

        mysql 分组合并值

            group_concat(要被合并的字段) ... group by 以谁为分组

        分组合并后去重 及 设置分隔符

            group_concat(distinct ... SEPARATOR ';') ... group by ...

        排序(不能和分隔符共同存在)

            group_concat(distinct ... desc) ... group by ...

   <19> 20200405 转 '2020-04-05'

        concat(substr(dt,1,4),'-',substr(dt,5,2),'-',substr(dt,7,2))

   <20> 视图(Hive,Oracle,Sql Server支持，Mysql不支持)

        临时视图表，减少重复sql代码

        WITH t1 AS (
                    SELECT *
                    FROM carinfo
                    ), 
             t2 AS (
                    SELECT *
                    FROM car_blacklist
                   )
       SELECT *
       FROM t1, t2;



三.1. 互联网


    1. 职位

        <1> 研发
        
            (1) BD 

                业务拓展和商务发展

            (2) SDE 

                高级软件开发工程师

            (3) RD

                研发工程师

                开发分工程与策略，工程搭建技术框架，提供服务。策略迭代算法。

        <2> 测试
        
            (1)SDET

                软件测试开发工程师

            (2) QA 

                Quality Assurance

                质量把控

        <3> 产品
        
            (1) PM

                项目经理

        <4> 数据
        
            (1) DSI 

                Data Science Intellgence

                数据科学与智能

        <5> 运营
        
            (1) BP

                business partnter 业务合作伙伴


    2. 工具

        <1> PRD 与 DRD (同是需求文档) 

            PRD : PRD是产品需求文档，描述了该产品的大方向。 - 产品大方向

            DRD : DRD是交互设计文档，用来承载交互说明，并交付给前端、测试以及开发工程师参考的文档。- 产品细节


    3. 概念

        <1> B端、C端 

            Consumer 个人用户端  To C

            Business 商家用户端  To B

        <2> O2O 
 
            Online To Offline 线上到线下

            O2O闭环，用户从线上到线下，最后再回到线上，只有这样，O2O才成为真正的O2O，而不是单纯的广告平台或分类信息提供者


        
四.1.1 开发


    <1> API 

        应用程序编程接口

        接口，通过API交给一个程序，程序返回一个内容

    <2> SDK

        软件开发工具包

        在本地建立程序，内容传入程序中产出内容

    <3> 日志

        操作系统或软件运行时存下来的过程数据

        日志数据就是计算机操作系统、或者有些应用软件在运行时，为了在今后进行系统维护起来比较方便，而将系统、或者应用软件在运行过程中产生的各种数据（通常是：用户名、用户执行的程序名、日期、时间等）写入到一个日志文件中（通常都是以 *.log　结尾）。以便今后系统出故障时可以有据可查。

    <4> kafka

        日志系统

    <5> 灰度测试

        未上线 : 黑

        中间   : 灰

        上线   : 白

    作用 :

        在某项产品或应用正式发布前，选择特定人群试用，逐步扩大其试用者数量，以便及时发现和纠正其中的错误。

        并可以 满足部分用户抢先体验的愿望

        还可以 收集用户体验的数据与指标，获得用户的意见反馈，完善产品功能，提升产品质量。


四.2. 英 文 

    
    1. 数据分析英文
        
        <1> outliers

            异常值

        <2> insight 

            洞察

    2. 互联网常用英文
    
        <1> banner 

            广告横幅


四.3. Mac 


     1. 常用指令
        
        <1> Mac brew 安装

            https://www.cnblogs.com/x1you/p/12506405.html

        <2> uname -a

            查看操作系统的版本

        <3> 查看文件的版本  

            file 文件


四.4. 疑问 


    <1> 权重如何分配


四.4.5 其 他 


    <1> 人次

        一个人多次会重复计算，按次数计算

        人数

        一个人不重复计算，按人数计算

        uv : 计算uv，在去重时，子项上钻需要将去重字段叠加到一起再去重。

    <2> hadoop 常用指令

        hadoop fs -get /user/map_da/map_bi/XXXXX/xxxx.sh   ###hdfs下载文件
        hadoop fs -put   xxxx.sh    /user/map_da/map_bi/XXXXX/    ####上传本地文件至hdfs
        hadoop fs -rm  /user/map_da/map_bi/XXXXX/xxxx.sh    ####删除远端hdfs文件
        hadoop fs -cat /user/map_da/map_bi/XXXXX/xxxx.sh   ###预览hdfs文件
        hadoop fs -mkdir /user/map_da/map_bi/XXXXX/dir    ###hdfs上新建目录
        hadoop fs -ls /user/map_da/map_bi/XXXXX/dir   ###查看hdfs目录信息
        hadoop fs -du -h /user/map_da/map_bi/XXXXX/dir   ###查看hdfs目录下文件大小

    <3> CRM 客户关系管理

        Customer Relationship Management
